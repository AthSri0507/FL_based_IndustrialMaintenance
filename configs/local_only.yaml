# Local-Only Baseline Configuration
# Each client trains independently on their own data without federation

# Data settings
data_dir: "data/raw"
data_files: []  # Empty = auto-detect all files
window_size: 50
hop_size: 10
normalize_windows: true
global_test_split: 0.15  # Held-out test set for fair comparison

# Client settings
num_clients: 5
heterogeneity_mode: "uniform"  # Options: "uniform", "dirichlet", "extreme"
dirichlet_alpha: 0.5  # Lower = more heterogeneous (for dirichlet mode)
# extreme_imbalance: [0.9, 0.7, 0.5, 0.3, 0.1]  # Fault prevalence per client

# Task settings
task: "rul"  # "rul" or "classification"
num_classes: 2

# Model architecture (matches centralized for fair comparison)
num_layers: 4
hidden_dim: 64
kernel_size: 3
dropout: 0.2
fc_hidden: 32

# Training settings (per client)
local_epochs: 20
batch_size: 16
lr: 0.001
weight_decay: 0.0001
optimizer: "adam"
early_stopping_patience: 5
early_stopping_min_delta: 0.0001

# RUL normalization
normalize_rul: true
rul_max: null  # Auto-detect from data

# Reproducibility
seed: 42
deterministic: true

# Output
output_dir: "experiments/outputs/local_only"
save_client_models: true
compare_centralized: true
centralized_checkpoint: ""  # Path to centralized model

# Hardware
device: "auto"
